{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informal ReadMe: \n",
    "- My top priority is not scalabilty (yet) \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michael's Advice: \n",
    "    # One df per patient\n",
    "    # Pivot? Get dummies?\n",
    "    # Rolling Window   !!! Ben said 3 second window is best\n",
    "    \n",
    "# JM's Advice: \n",
    "    # Write a function to bring in all the data\n",
    "    # Have it make a patient column and doc column\n",
    "    # But getting an MVP could be super useful too. \n",
    "        # So if you want to try the experiment on pt 1, that's good too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation with patient #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPG #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPG1 = pd.read_csv('Barretts_Analysis/CPG/001 CPG.csv', skiprows = 7).fillna(' ')\n",
    "# Maybe don't need fillna()\n",
    "\n",
    "# Create a new variable called 'header' from the first row of the dataset\n",
    "header = CPG1.iloc[0]\n",
    "header = header.str.replace('\\n', ' ')\n",
    "CPG1 = CPG1.rename(columns = header)\n",
    "CPG1 = CPG1[1:]\n",
    "\n",
    "CPG1 = CPG1.drop(columns = ['Position from LES (cm)', 'BCT (sec)', 'pH Delta (pH)', 'ACT (sec)'])\n",
    "\n",
    "CPG1 = CPG1[CPG1[\"Meas Type\"].str.contains(\"MII\")]\n",
    "CPG1 = CPG1.rename(columns={'Meas Start Time': 'CPG Start Time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto1 = pd.read_csv('Barretts_Analysis/Autoscan/001 Autoscan.csv', skiprows = 7).fillna(' ')\n",
    "# Maybe don't need fillna()\n",
    "\n",
    "# Create a new variable called 'header' from the first row of the dataset\n",
    "header = Auto1.iloc[0]\n",
    "header = header.str.replace('\\n', ' ')\n",
    "Auto1 = Auto1.rename(columns = header)\n",
    "Auto1 = Auto1[1:]\n",
    "\n",
    "Auto1 = Auto1.drop(columns = ['Position from LES (cm)', 'BCT (sec)', 'pH Delta (pH)', 'ACT (sec)'])\n",
    "\n",
    "Auto1 = Auto1[Auto1[\"Meas Type\"].str.contains(\"MII\")]\n",
    "Auto1 = Auto1.rename(columns={'Meas Start Time': 'Auto Start Time'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CPG1['MII Reflux'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CPG1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Auto1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1: merge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TestCPGAuto = pd.merge(CPG1, Auto1, how = 'outer')\n",
    "# Ugly result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I'm missing rows now (a lot of them) and all these NaN's were thrown in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2: Concatenating CPG + Auto - Patient 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCPGAuto2 = pd.concat([CPG1, Auto1], axis = 1).fillna('').drop(columns = {'Meas Type', 'Body Position', 'Contents'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TestCPGAuto2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCPGAuto2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a Doc column again and stack vertically, you could sort by start time. \n",
    "# Probably need Start Day and Start Time re.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCPGAuto2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3: Concatenate vertically - CPG, Auto - Patient 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPG1b = pd.read_csv('Barretts_Analysis/CPG/001 CPG.csv', skiprows = 7).fillna(' ')\n",
    "# Maybe don't need fillna()\n",
    "\n",
    "# Create a new variable called 'header' from the first row of the dataset\n",
    "header = CPG1b.iloc[0]\n",
    "header = header.str.replace('\\n', ' ')\n",
    "CPG1b = CPG1b.rename(columns = header)\n",
    "CPG1b = CPG1b[1:]\n",
    "\n",
    "CPG1b = CPG1b.drop(columns = ['Position from LES (cm)', 'BCT (sec)', 'pH Delta (pH)', 'ACT (sec)'])\n",
    "\n",
    "CPG1b = CPG1b[CPG1b[\"Meas Type\"].str.contains(\"MII\")]\n",
    "CPG1b['Doc'] = 'CPG'\n",
    "\n",
    "Auto1b = pd.read_csv('Barretts_Analysis/Autoscan/001 Autoscan.csv', skiprows = 7).fillna(' ')\n",
    "# Maybe don't need fillna()\n",
    "\n",
    "# Create a new variable called 'header' from the first row of the dataset\n",
    "header = Auto1b.iloc[0]\n",
    "header = header.str.replace('\\n', ' ')\n",
    "Auto1b = Auto1b.rename(columns = header)\n",
    "Auto1b = Auto1b[1:]\n",
    "\n",
    "Auto1b = Auto1b.drop(columns = ['Position from LES (cm)', 'BCT (sec)', 'pH Delta (pH)', 'ACT (sec)'])\n",
    "\n",
    "Auto1b = Auto1b[Auto1b[\"Meas Type\"].str.contains(\"MII\")]\n",
    "Auto1b['Doc'] = 'Auto'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CPG1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCPGAuto3 = pd.concat([CPG1b, Auto1b]).fillna('').drop(columns = {'Meas Type', 'Body Position', 'Contents'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCPGAuto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCPGAuto3.Doc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: \n",
    "    # If you have a Doc column again and stack vertically, you could sort by start time. \n",
    "    # Probably need Start Day and Start Time re.split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore \n",
    "\n",
    "pd.set_option('display.max_rows', 76)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# df.sort_values(by='Date')\n",
    "\n",
    "TestCPGAuto3.sort_values(by = 'Meas Start Time').reset_index().rename(columns = {'index': 'Old Index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Could I write a function to read in the files and label them with the patient number? And Doc name? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do I still need to split the start time? Should it be a datetime object? \n",
    "\n",
    "* Could you do ML to find out who is predicting better? Reflux = 1, No Reflux = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to bring in all data & label accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = 'Barretts_Analysis/'\n",
    "next_path = glob.glob(path + \"*\")\n",
    "#all_files = glob.glob(next_path + \"/*.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     li.append(df)\n",
    "\n",
    "# frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "# command + ? = BIG comment\n",
    "\n",
    "li = []\n",
    "\n",
    "for some_path in next_path: \n",
    "    #print(some_path) \n",
    "    if some_path == 'Barretts_Analysis/AI': \n",
    "        continue\n",
    "    else: \n",
    "        for file in glob.glob(some_path + \"/*.csv\"):\n",
    "            #print(file)\n",
    "            df = pd.read_csv(file, index_col=None, header=0, skiprows = 7).fillna('-')\n",
    "            header = df.iloc[0]\n",
    "            header = header.str.replace('\\n', ' ')\n",
    "            df = df.rename(columns = header)\n",
    "            df = df[1:]\n",
    "            df = df.drop(columns = ['Position from LES (cm)', 'BCT (sec)', 'pH Delta (pH)', 'ACT (sec)'])\n",
    "            df = df[df[\"Meas Type\"].str.contains(\"MII\")]\n",
    "            #df['patient_number'] = file.replace('/', ' ')\n",
    "            df['z_filename'] = file.replace(' ', '-')\n",
    "            #df['z_filename'] = df['z_filename'].dropna()\n",
    "            #print(df.head())\n",
    "            li.append(df)\n",
    "        \n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "# command + ? = BIG comment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I don't have my doc name or patient number....!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.z_filename.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.z_filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['patient_num','doc', 'None', 'None']] = frame.z_filename.str.split(\"-\",expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['folder1', 'doctor', 'patient']] = frame.patient_num.str.split('/', expand = True).replace('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['patient2'] = frame.patient_num.str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.drop(columns = {'Meas Type', 'Body Position', 'Contents', 'patient_num', 'doc', 'None', 'folder1', 'z_filename', 'patient', '-'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split meas start time and convert to datetime. Convert to 24 hour? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.set_option('display.max_rows', 9091)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.patient2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.doctor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['Meas Start Day', 'Meas Start Time']] = frame['Meas Start Time'].str.split(\"/\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe \n",
    "\n",
    "# frame['Meas Start Time 2'] = pd.to_datetime(frame['Meas Start Time'], format = '%H:%M:%S.%f')\n",
    "#frame['Meas Start Time 2'] = pd.to_datetime(frame['Meas Start Time'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore \n",
    "\n",
    "frame['date_only'] = frame['Meas Start Time 2'].dt.date\n",
    "frame['time_only'] = pd.to_timedelta(frame['Meas Start Time 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore \n",
    "\n",
    "frame = frame.drop(columns = {'date_only'})\n",
    "#frame = frame.drop(columns = {'Meas Start Time 2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore \n",
    "\n",
    "df['normalised_date'] = df['dates'].dt.normalize()\n",
    "\n",
    "frame['Meas Start Time 2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame['Meas Start Time 2'].str.strip('T00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dibran's code for shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['Meas Start TimeStamp'] = pd.to_datetime(frame['Meas Start Time'])\n",
    "frame['3_second_shift'] = frame['Meas Start TimeStamp'] + timedelta(seconds = -3)\n",
    "frame['3_second_shift_forward'] = frame['Meas Start TimeStamp'] + timedelta(seconds = 3)\n",
    "frame['3_second_target'] = 0\n",
    "new_frame = frame.groupby('doctor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filtered_rows = pd.DataFrame([])\n",
    "for k in new_frame.groups.keys():\n",
    "    data = new_frame.get_group(k)\n",
    "    for x, y in data.iterrows():\n",
    "        if y['MII Reflux'] =='Reflux':\n",
    "            the_only_hope = data[(data['Meas Start TimeStamp'] > y['3_second_shift'])&\n",
    "                              (data['Meas Start TimeStamp'] < y['Meas Start TimeStamp'])]\n",
    "        else: \n",
    "            continue\n",
    "    filtered_rows = filtered_rows.append(the_only_hope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frame = frame.sort_values(by=['patient2'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['Meas Start Day'] = frame['Meas Start Day'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.sort_values([\"patient2\", \"Meas Start Day\", \"Meas Start Time\"], ascending = (True, True, True))\n",
    "frame.head()\n",
    "# consider using 4 seconds instead of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore \n",
    "\n",
    "frame[frame.duplicated(['Meas Start Time'])]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ignore \n",
    "\n",
    "frame[frame['Meas Start Time']=='17:46:11.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort by (patient?) then by meas time , write a func starting on first row and iterate through rows, for each row, see if next row occurs within three sec. If yes, label meas. if not, increase by one\n",
    "\n",
    "## dont forget same day, same patient "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frame.between_time(frame['3_second_shift'], frame['3_second_shift_forward'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if current_item_time is +- 3 sec of previous_item_time: \n",
    "    and Meas Start Day == previous Meas Start Day:\n",
    "        label Measurement (n)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from itertools import islice\n",
    "\n",
    "def window(seq, n=2):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, frame in df['Meas Start TimeStamp'].iteritems():\n",
    "    if next <= '00:00:03.000':\n",
    "        print frame\n",
    "        2020-05-14 16:12:40.400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(df[1].ge(df[1].shift())) & df[1].le(df[1].shift(-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_row(df):\n",
    "\n",
    "    if df['Meas Start Time'].current == df['Meas Start Time'].next:\n",
    "        df['Meas No.']' = 1\n",
    "    elif df['Meas Start Time'].next <= 3s of df['Meas Start Time'].current:\n",
    "        df['Meas No.'] = '1'\n",
    "    else df['Meas No.'].value = df['Meas No.'].next\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_row_2(df):\n",
    "    for row in df.iterrows:\n",
    "        if (row['Meas Start TimeStamp'].next - row['Meas Start TimeStamp'].current).dt.total_seconds() <= 3.00:\n",
    "            row['Meas No.'] = 1\n",
    "        else: \n",
    "            row['Meas No.'] = row['Meas No.'] + 1          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested loop, use groupbys instead of for loops (grupby patient and day)\n",
    "Pandas.cut to do a groupby arange on time\n",
    "for each group, iterate over the groups and add labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_pt_dy = frame.groupby(['patient2', 'Meas Start Day'])\n",
    "\n",
    "for patient, startday in by_pt_dy: \n",
    "    print(f\"First 2 entries for {patient!r}\")\n",
    "    print(\"------------------------\")\n",
    "    print(startday.head(2), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame['Meas Start Day'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
